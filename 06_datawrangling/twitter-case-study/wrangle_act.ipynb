{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API Scraping and Data Wrangling Case Study\n",
    "Timothy Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import tweepy #pip install tweepy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load archived tweets\n",
    "df_tweets = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "print(df_tweets.shape[0])\n",
    "df_tweets.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset for images\n",
    "images_url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "images = requests.get(images_url)\n",
    "with open('image_predictions.tsv', mode='wb') as file:\n",
    "    file.write(images.content)\n",
    "df_predictions = pd.read_csv('image_predictions.tsv', delimiter='\\t')\n",
    "df_predictions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "#### Step 2: Investigate and Observe the Tweets Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[df_tweets['rating_denominator']!=10].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[df_tweets['rating_numerator'] > 15]['rating_numerator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[df_tweets['name'] == 'None'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.query(\n",
    "    'doggo == \"None\"'  and 'floofer == \"None\"' and 'pupper == \"None\"' and 'puppo == \"None\"'\n",
    "        ).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for different values of dog stages\n",
    "print(df_tweets[df_tweets['doggo'] != \"None\"]['doggo'].value_counts())\n",
    "print(df_tweets[df_tweets['floofer'] != \"None\"]['floofer'].value_counts())\n",
    "print(df_tweets[df_tweets['pupper'] != \"None\"]['pupper'].value_counts())\n",
    "print(df_tweets[df_tweets['puppo'] != \"None\"]['puppo'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- 181 of the tweets were \"retweeted\" and 78 of the tweets were \"replies\"\n",
    "- `tweet_id` is as an Integer; should be a String\n",
    "- `timestamp` field is a String (not in DateTime), same is true for `retweeted_status_timestamp`\n",
    "- `expanded_urls` (the URL of the photo) is missing in 59 tweets\n",
    "- `text` field contains multiple data points (actual text, rating, url, and dog name)\n",
    "- `rating_denominator` has 23 records with a value other than 10\n",
    "- `rating_numerator` has widely ranging values\n",
    "- `name` has 745 records with 'None' as the dog name\n",
    "- There are 2326 records where the dog stage was not identified (as `doggo, floofer, pupper, puppo`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "#### Step 3: Clean the Tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy the tweets dataframe\n",
    "df_tweets_copy = df_tweets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change tweet_id to String\n",
    "df_tweets_copy['tweet_id'] = df_tweets_copy['tweet_id'].astype(str)\n",
    "\n",
    "#remove retweets\n",
    "df_tweets_copy = df_tweets_copy[df_tweets_copy['retweeted_status_id'].isnull()]\n",
    "\n",
    "#remove replies\n",
    "df_tweets_copy = df_tweets_copy[df_tweets_copy['in_reply_to_status_id'].isnull()]\n",
    "\n",
    "#remove tweets with no photos\n",
    "df_tweets_copy = df_tweets_copy[df_tweets_copy['expanded_urls'].notnull()]\n",
    "\n",
    "#change timestampe to DateTime\n",
    "df_tweets_copy['timestamp'] = pd.to_datetime(df_tweets_copy['timestamp'])\n",
    "\n",
    "df_tweets_copy.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean extracted data - rating\n",
    "#look for denominators other than 10\n",
    "pd.options.display.max_colwidth = 150\n",
    "df_tweets_copy[df_tweets_copy['rating_denominator'] != 10][['text', 'rating_numerator', 'rating_denominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually update errors - based on denominator\n",
    "df_tweets_copy.set_value(851, 'rating_numerator', 9);\n",
    "df_tweets_copy.set_value(946, 'rating_numerator', 13);\n",
    "df_tweets_copy.set_value(1423, 'rating_numerator', 10);\n",
    "df_tweets_copy.set_value(2073, 'rating_numerator', 9);\n",
    "df_tweets_copy.set_value([851, 946, 1423, 2073], 'rating_denominator', 10);\n",
    "\n",
    "df_tweets_copy.drop(402, inplace=True)\n",
    "df_tweets_copy.reset_index()\n",
    "\n",
    "#update ratings for photos of multiple dogs - look for deniminators greater than 10 in multiples of 10\n",
    "for row in df_tweets_copy[df_tweets_copy['rating_denominator'] != 10][['text', 'rating_numerator', 'rating_denominator']].itertuples():\n",
    "    divisor = row.rating_denominator / 10\n",
    "    new_rating = row.rating_numerator / divisor\n",
    "    index = row[0]\n",
    "    df_tweets_copy.set_value(index, 'rating_numerator', new_rating)\n",
    "    df_tweets_copy.set_value(index, 'rating_denominator', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#look for large denominators - greater than 15\n",
    "df_tweets_copy[df_tweets_copy['rating_numerator'] > 15][['text', 'rating_numerator', 'rating_denominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually update errors\n",
    "df_tweets_copy.set_value(527, 'rating_numerator', 9.75);\n",
    "df_tweets_copy.set_value(584, 'rating_numerator', 11.27);\n",
    "df_tweets_copy.set_value(1471, 'rating_numerator', 11.26);\n",
    "\n",
    "#remove errors\n",
    "df_tweets_copy.drop(768, inplace=True)\n",
    "df_tweets_copy.drop(1818, inplace=True)\n",
    "df_tweets_copy.reset_index();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "#### Step 4: Download Twitter Data through API and Merge with Tweet Dataset\n",
    "Download data from Twitter using Tweepy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter API\n",
    "f_keys = open('keys.txt', 'r')\n",
    "\n",
    "keys = {}\n",
    "keys['consumer_key'] = f_keys.readline().rstrip()\n",
    "keys['consumer_secret'] = f_keys.readline().rstrip()\n",
    "keys['access_token'] = f_keys.readline().rstrip()\n",
    "keys['access_secret'] = f_keys.readline().rstrip()\n",
    "\n",
    "f_keys.close()\n",
    "\n",
    "auth = tweepy.OAuthHandler(keys['consumer_key'], keys['consumer_secret'])\n",
    "auth.set_access_token(keys['access_token'], keys['access_secret'])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read tweets via tweepy API\n",
    "data = {}  \n",
    "data['tweets'] = []\n",
    "start = time.time()   \n",
    "#for twitters in df_tweets_copy.iloc[0:5].itertuples(): for testing\n",
    "for twitters in df_tweets_copy.iloc[:].itertuples():\n",
    "    try:\n",
    "        tweet = api.get_status(twitters.tweet_id)\n",
    "        retweets = tweet.retweet_count\n",
    "        favorites = tweet.favorite_count\n",
    "    except Exception:\n",
    "        tweet = twitters.tweet_id\n",
    "        retweets = float('NaN')\n",
    "        favorites = float('NaN')\n",
    "    \n",
    "    data['tweets'].append({\n",
    "                    'retweets' : retweets,\n",
    "                    'favorites' : favorites,\n",
    "                    'tweet_id' : twitters.tweet_id\n",
    "                      })\n",
    "\n",
    "end = time.time()\n",
    "print('elapsed %f' %(end - start))\n",
    "    \n",
    "#write json info to tweet_json.txt\n",
    "with open('tweet_json.txt', 'w') as outfile:  \n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read json file\n",
    "tweet_info = []\n",
    "with open('tweet_json.txt') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    for p in data['tweets']:\n",
    "        tweet_info.append(p)\n",
    "\n",
    "df_twitter_api = pd.DataFrame(tweet_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge dataframes from Twitter archives, Tweepy API downloads, and predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api.info();\n",
    "df_twitter_api.head(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_copy.info()\n",
    "df_tweets_copy.head(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['tweet_id'] = df_predictions['tweet_id'].astype(str)\n",
    "df_predictions.info()\n",
    "df_predictions.head(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dataframes\n",
    "df_master = df_twitter_api.merge(df_tweets_copy, on='tweet_id').merge(df_predictions, on='tweet_id')\n",
    "df_master['timestamp'] = pd.to_datetime(df_master['timestamp'])\n",
    "df_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export to twitter_archive_master.csv\n",
    "df_master.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "#### Step 5: Analyze Data & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_master = pd.read_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_master['timestamp'] = pd.to_datetime(df_master['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_master['favorites'], range=[0,50000], bins=20);\n",
    "plt.title('Distribution of Tweets \"Favorited\"');\n",
    "plt.xlabel('Favorites');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_master['retweets'], range=[0,25000], bins=20);\n",
    "plt.title('Distribution of Tweets \"Retweeted\"');\n",
    "plt.xlabel('Retweets');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_master['rating_numerator']);\n",
    "plt.title('Distribution of Ratings');\n",
    "plt.xlabel('Ratings');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_master['favorites'], df_master['rating_numerator'], alpha=.2)\n",
    "plt.title('Rating vs Favorites')\n",
    "plt.ylabel('Rating');\n",
    "plt.xlabel('Favorites');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = ('doggo', 'floofer', 'pupper', 'puppo')\n",
    "heights = [df_master[df_master['doggo'] == \"doggo\"]['rating_numerator'].mean(),\n",
    "          df_master[df_master['floofer'] == \"floofer\"]['rating_numerator'].mean(),\n",
    "          df_master[df_master['pupper'] == \"pupper\"]['rating_numerator'].mean(),\n",
    "          df_master[df_master['puppo'] == \"puppo\"]['rating_numerator'].mean(),\n",
    "          ]\n",
    "plt.bar([1,2,3,4], heights, tick_label=xlabels);\n",
    "plt.title('Average Rating by Dog Stage');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_master['timestamp'].dt.hour, bins=24);\n",
    "plt.xlabel('Hour (24)');\n",
    "plt.ylabel('Number of Tweets');\n",
    "plt.xticks((0,3,7,11,15,19,23));\n",
    "plt.title('Distribution of Tweets Across Time of Day');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_master['timestamp'].dt.hour, df_master['favorites'], alpha=.2);\n",
    "plt.xlabel('Hour (24)');\n",
    "plt.ylabel('Number of \"Favorites\"');\n",
    "plt.xticks((0,3,7,11,15,19,23));\n",
    "plt.title('Distribution of \"Favorited\" Tweets Across Time of Day');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = ('first (p1)', 'second (p2)', 'third (p3)', 'none')\n",
    "heights = [df_master[df_master['p1_dog'] == True]['rating_numerator'].mean(),\n",
    "          df_master[df_master['p2_dog'] == True]['rating_numerator'].mean(),\n",
    "          df_master[df_master['p3_dog'] == True]['rating_numerator'].mean(),\n",
    "          df_master.query('p1_dog == False' and 'p2_dog == False' and 'p3_dog == False')['rating_numerator'].mean(),\n",
    "          ]\n",
    "plt.bar([1,2,3,4], heights, tick_label=xlabels);\n",
    "plt.title('Rating by Algorithm Effectiveness');\n",
    "plt.xlabel('Algorithm Succesfully Picked');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_master['p1_conf'], df_master['rating_numerator'], alpha=.1, s=30);\n",
    "plt.title('Rating by Predictive Algorithm\\n(Based on confidence of p1)');\n",
    "plt.xlabel('Confidence of Algorithm (p1)');\n",
    "plt.ylabel('Rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the effectiveness of the algorithm\n",
    "accuracy = []\n",
    "for i in range(10,100, 10):\n",
    "    df_sample = df_master.query('p1_conf < ' + str(i/100))\n",
    "    score = (1 - df_sample['p1_dog'].value_counts()[0] / df_sample['p1_dog'].shape[0])\n",
    "    accuracy.append(score)\n",
    "    print('Accuracy at %s%% ' %i, score)\n",
    "\n",
    "plt.scatter((.1,.2,.3,.4,.5,.6,.7,.8,.9), 100*numpy.array(accuracy));\n",
    "plt.title('Accuracy of Algorithm');\n",
    "plt.xlabel('Confidence of Algorithm (p1)');\n",
    "plt.ylabel('Accuracy Percentage');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
